{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Friday - Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Importing required libraries and Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-26853d55a61c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ggplot'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# URL for style sheets (https://matplotlib.org/gallery/style_sheets/style_sheets_reference.html)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'axes.titlesize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'axes.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xtick.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ytick.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('ggplot') # URL for style sheets (https://matplotlib.org/gallery/style_sheets/style_sheets_reference.html)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'\n",
    "%matplotlib inline\n",
    "\n",
    "# warning settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data into python from the given csv file\n",
    "train = pd.read_csv('../data/BlackFriday/train.csv')\n",
    "test = pd.read_csv('../data/BlackFriday/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including new column named 'source' and giving the value as 'train' / 'test' to identify from where exactly the data was taken\n",
    "train['source']='train'\n",
    "test['source']='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the 2 dataframes (train and Test) into a single dataframe 'dataset'\n",
    "dataset = pd.concat([train, test],ignore_index=True, sort=False)\n",
    "print (train.shape, test.shape, dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values in the columns\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__:\n",
    "There are significant missing values in 3 columns (Product_Category_2, Product_Category_3 and Purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking details from the columns with 'numeric' datatype\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the columns are with categorical data, either expressed in numericals or strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining number of unique values in each column\n",
    "dataset.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter categorical variables\n",
    "categorical_columns = [x for x in dataset.dtypes.index if dataset.dtypes[x]=='object']\n",
    "# Adding other categorical variables indicated as numerics\n",
    "categorical_columns.extend(['Occupation'])\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping Identifier values from the list\n",
    "categorical_columns = [x for x in categorical_columns if x not in ['Product_ID','source']]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print frequency of categories\n",
    "for col in categorical_columns:\n",
    "    print ('Frequency (Count) of Categories for varible : ', col)\n",
    "    print (dataset[col].value_counts())\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observations of the column headers and the values the following hypothesis can be carried out\n",
    "\n",
    "__User_ID__ : <br>\n",
    "Identification values which links to the demographics of the person like (Gender, Age, Marital Status, Occupation, City Category and years in city) \n",
    "<br>\n",
    "\n",
    "__Product_ID__ : <br>\n",
    "Identification values which links other sub categories Product_Category_1, Product_Category_2 and Product_Category_3\n",
    "<br>\n",
    "\n",
    "__Gender__ : (Male / Female) <br>\n",
    "Generally females shop more than male. However the User_ID maybe linked with the male who would pay for the purchase\n",
    "<br>\n",
    "\n",
    "__Age__ : (Range between 0 to 55+) <br>\n",
    "Teenagers and middle aged group people tend to make use of the BlackFriday sale\n",
    "<br>\n",
    "\n",
    "__Marital Status__ : (Married / Un-married) <br>\n",
    "Un-married people spend more during the sale season compared to those married\n",
    "<br>\n",
    "\n",
    "__Occupation__ : (Range between 0 to 20) <br>\n",
    "People in Managerial and above position Purchase more compared to mid-level and associate positions\n",
    "<br>\n",
    "\n",
    "__City Category__ : (Code A, B, C) <br>\n",
    "People living in metros spend more during sale compared to less populated cities\n",
    "\n",
    "__Stay in City__ : (Range between 0 to 4+) <br>\n",
    "As people stay more in a particular city and based on experience on various aspects in the mart, people who fancy few of their favorite marts may visit them during the sale season.\n",
    "\n",
    "__Product Category__ : (1, 2, & 3) <br>\n",
    "Links to Sub categories of Product_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA\n",
    "> Imputing missing values and Treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether Product_ID is related to other Product Category columns\n",
    "dataset.groupby(['Product_ID'])['Product_Category_1','Product_Category_2','Product_Category_3'].mean().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: <br>\n",
    "From the above, we can make out that Product_Category2 and Product_Category3 are __not related__ to the Product_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining list of booleans specifying Product_Category_2 and Product_Category_3 missing  values\n",
    "miss_Prod2_rows = dataset['Product_Category_2'].isnull()  \n",
    "miss_Prod3_rows = dataset['Product_Category_3'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 0s in place of NaN in columns Product_Category_2 and Product_Category_3\n",
    "dataset.loc[miss_Prod2_rows,'Product_Category_2'] = 0\n",
    "dataset.loc[miss_Prod3_rows,'Product_Category_3'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Product_ID','Product_Category_1','Product_Category_2','Product_Category_3']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining 3 Product category columns into 1 maseter category column\n",
    "dataset['Master_Product_Category']=dataset['Product_Category_1'].astype(str)+dataset['Product_Category_2'].astype(int).astype(str)+dataset['Product_Category_3'].astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Product_ID','Product_Category_1','Product_Category_2','Product_Category_3','Master_Product_Category']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purchase column__ : <br>\n",
    ">There are quire a few missing values in Purchase (dependent varaible) column. <br>\n",
    "It is advisable to impute as many values in the dependent variable column to obtain a good model.<br>\n",
    "Hence it is advisable to find whether there is *correlation between the Product_ID or newly created Master Product Category column* and Purchase column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Purchase values from the grouping by the newly created Master_Product_Category column\n",
    "categ_mean = dataset.groupby(['Master_Product_Category'])['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Purchase values from the grouping by the Product_ID column\n",
    "purch_mean_prodID = dataset.groupby(['Product_ID'])['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purch_mean_prodID.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the missing values in Purchase column has corresponding Master category values, <br>\n",
    "incorporating the mean value into the Purchase column based on the Master Category column is advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain missing Purchase values\n",
    "miss_Purch_rows = dataset['Purchase'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute mean Purchase value based on Master_Product_Category column\n",
    "dataset.loc[miss_Purch_rows,'Purchase'] = dataset.loc[miss_Purch_rows,'Master_Product_Category'].apply(lambda x: categ_mean.loc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Null values in Purchase column before imputation : ' , miss_Purch_rows.sum())\n",
    "print ('Results after imputation : ', dataset['Purchase'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "dataset = dataset[['User_ID','Product_ID', 'Gender','Age','Occupation', 'City_Category','Stay_In_Current_City_Years',\n",
    "                   'Marital_Status',  'Master_Product_Category', 'Purchase', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Master_Product_Category datatype object to integer\n",
    "dataset['Master_Product_Category'] = dataset['Master_Product_Category'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Gender to more intuitive categories:\n",
    "dataset['Gender'] = dataset['Gender'].map({'F':'Female','M':'Male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Marital_Status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename them to more intuitive categories:\n",
    "dataset['Marital_Status'] = dataset['Marital_Status'].map({0:'Un-Married', 1:'Married'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-look at the unique values of other 'demographical' columns pertaining to the customer\n",
    "print('Age :' ,sorted(dataset.Age.unique()), sep='\\n')\n",
    "print(sep='\\n\\n')\n",
    "print('City_Category :', sorted(dataset.City_Category.unique()), sep='\\n')\n",
    "print(sep='\\n\\n')\n",
    "print('Stay_In_Current_City_Years :', sorted(dataset.Stay_In_Current_City_Years.unique()), sep='\\n')\n",
    "print(sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing '4+' years of with numerical number 4 \n",
    "dataset['Stay_In_Current_City_Years'] = dataset['Stay_In_Current_City_Years'].replace('4+', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Stay_In_Current_City_Years data type to integer\n",
    "dataset['Stay_In_Current_City_Years'] = dataset['Stay_In_Current_City_Years'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Occupation :', sorted(dataset.Occupation.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Point to ponder__:\n",
    "\n",
    "We can observe that there are __(21) categories__ of Occupation of customers. <br>\n",
    "Based on the country that the data has been taken, there might be standard coding system for categorising occupation, which is been indicated in the dataset.\n",
    "\n",
    "However, based on International Standard Classification of Occupations, there are (10) main categories\n",
    "1. Managers\n",
    "2. Professional\n",
    "3. Technicians and associate professionals\n",
    "4. Clerical support workers\n",
    "5. Service and sales workers\n",
    "6. Skilled agricultural, forestry and fishery workers\n",
    "7. Craft and related trades workers\n",
    "8. Plant and machine operators, and assemblers\n",
    "9. Elementary occupations\n",
    "10. Armed forces occupations\n",
    "\n",
    "(Source : Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of categorical variables  - __BY COUNT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Pie chart for gender distribution\n",
    "plt.subplot(2,2,1)\n",
    "gender_count = [dataset.Gender[dataset['Gender']=='Female'].count(),\n",
    "                dataset.Gender[dataset['Gender']=='Male'].count()]\n",
    "gender_lab = dataset.Gender.unique()\n",
    "expl = (0.1,0)\n",
    "plt.pie(gender_count, labels=gender_lab, explode=expl, shadow=True , autopct='%1.1f%%');\n",
    "\n",
    "# Bar chart for Age\n",
    "plt.subplot(2,2,2)\n",
    "ordr =dataset.groupby([\"Age\"]).count().sort_values(by='Purchase',ascending=False).index\n",
    "sns.countplot(dataset['Age'], label=True, order=ordr)\n",
    "\n",
    "# Bar chart for Occupation\n",
    "plt.subplot(2,2,3)\n",
    "ordr1 =dataset.groupby([\"Occupation\"]).count().sort_values(by='Purchase',ascending=False).index\n",
    "sns.countplot(y=dataset['Occupation'], label=True, order=ordr1)\n",
    "\n",
    "# Donut chart for City Category\n",
    "plt.subplot(2,2,4)\n",
    "city_group = dataset.groupby([\"City_Category\"])\n",
    "city_count = city_group[['Purchase']].count().values.tolist()\n",
    "city_lab = dataset.groupby([\"City_Category\"]).count().index.values\n",
    "my_circle = plt.Circle( (0,0), 0.4, color='white')\n",
    "expl1 = (0,0.1,0)\n",
    "plt.pie(city_count, labels=city_lab,explode=expl1, shadow=True, autopct='%1.1f%%')\n",
    "plt.gcf().gca().add_artist(my_circle)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "ordr2 =dataset.groupby([\"Stay_In_Current_City_Years\"]).count().sort_values(by='Purchase',ascending=False).index\n",
    "sns.countplot(dataset['Stay_In_Current_City_Years'], label=True, order=ordr2)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "ms_count = [dataset.Marital_Status[dataset['Marital_Status']=='Un-Married'].count(),\n",
    "                dataset.Marital_Status[dataset['Marital_Status']=='Married'].count()]\n",
    "ms_lab = dataset.Marital_Status.unique()\n",
    "expl = (0.1,0)\n",
    "plt.pie(ms_count, labels=ms_lab, explode=expl, shadow=True , autopct='%1.1f%%');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Insight from Gender and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new column in the dataset \n",
    "dataset['Gender_MaritalStatus'] = dataset.apply(lambda x:'%s_%s' % (x['Gender'],x['Marital_Status']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Gender_MaritalStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "group_g_ms = dataset.groupby([\"Gender_MaritalStatus\"])\n",
    "count_ms = group_g_ms[['Purchase']].count().values.tolist()\n",
    "lab1 = dataset.groupby([\"Gender_MaritalStatus\"]).count().index.values\n",
    "expl2 = (0,0,0.1,0.1)\n",
    "\n",
    "plt.pie(count_ms, labels=lab1,explode=expl2, shadow=True, autopct='%1.1f%%')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(dataset['Age'],hue=dataset['Gender_MaritalStatus'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__ : \n",
    "1. __Un-married males__ between the age group of __26-35__ are major customers of the store.\n",
    "2. Majority customers are from the __City category B (42%) and C (31%)__\n",
    "4. Customers with __Occupation__ code __4 (13%), 0 (12.7%) and 7(10.8%)__ are more compared to others\n",
    "5. It can be observed that, as customers __who are new__ in the the current city, tend to purchase more from the store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of categorical variables  - __BY AVERAGE PURCHASE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "sns.catplot(x='Gender', y='Purchase', data=dataset, kind='boxen')\n",
    "\n",
    "ordr_age =dataset.groupby([\"Age\"]).mean().sort_values(by='Purchase',ascending=False).index\n",
    "sns.catplot(x='Age', y='Purchase', order=ordr_age, data=dataset, kind='bar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.catplot(x='City_Category', y='Purchase', data=dataset, kind='boxen')\n",
    "\n",
    "ordr_occ =dataset.groupby([\"Occupation\"]).mean().sort_values(by='Purchase',ascending=False).index\n",
    "sns.catplot(x='Occupation', y='Purchase', order=ordr_occ, data=dataset, kind='bar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__ : \n",
    "1. __Males__ spend more than females\n",
    "2. Age factor : Customers who are __above 35 years__ of age spend more. \n",
    "3. __Occupation codes 17, 12 and 15__ appears to be earning more and accordingly spend more \n",
    "4. People living in __Category C__ city appears to spend more on items in the store \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __Encoding categorical variable for - Correlation Visualation__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Encoding categorical columns to visualize correlation of parameters with Purchase column\n",
    "# Importing required package\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_x = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of the dataset for this activity\n",
    "dataset_cat = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical columns \n",
    "dataset_cat['Product_ID'] = encode_x.fit_transform(dataset_cat['Product_ID'])\n",
    "dataset_cat['Gender'] = encode_x.fit_transform(dataset_cat['Gender'])\n",
    "dataset_cat['Age'] = encode_x.fit_transform(dataset_cat['Age'])\n",
    "dataset_cat['City_Category'] = encode_x.fit_transform(dataset_cat['City_Category'])\n",
    "dataset_cat['Marital_Status'] = encode_x.fit_transform(dataset_cat['Marital_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cat[dataset_cat.columns[0:]].corr()['Purchase'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = dataset_cat.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=1, cmap=\"YlGnBu\", square=True,linewidths=.5, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top 5 parameters columns which affects the Purchase the most\n",
    "k= 5\n",
    "corrmat.nlargest(k, 'Purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replotting the heatmap with the above data\n",
    "cols = corrmat.nlargest(k, 'Purchase')['Purchase'].index\n",
    "cm = np.corrcoef(dataset_cat[cols].values.T)\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(cm, cmap=\"YlGnBu\", cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modifiying categorical variable__ <br>\n",
    "Combining cateogrical variables to obtain good number of counts of categorical varaibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building list of categorical variables to obtain details\n",
    "categ_columns = list(dataset.columns.values)\n",
    "categ_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping Identifier values, target values and others which are necessary from the list\n",
    "categ_columns = [x for x in categ_columns if x not in ['User_ID','Product_ID','Purchase','source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print frequency of categories\n",
    "for col in categ_columns:\n",
    "    print ('Frequency (Count) of Categories for varible : ', col)\n",
    "    print (dataset[col].value_counts())\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Combining Age ranges__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Modified_Age'] = dataset[['Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Modified_Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify Age Range to obtain obtain good number of counts in each range\n",
    "dataset['Modified_Age'] =dataset['Modified_Age']. map({'0-17':'0-25','18-25':'0-25',\n",
    "                                                       '46-50':'46-55+','51-55':'46-55+','55+':'46-55+',\n",
    "                                                      '26-35':'26-35','36-45':'36-45'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Modified_Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One Hot encoding of variables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "dataset[['Occupation','City_Category','Stay_In_Current_City_Years','Gender_MaritalStatus','Modified_Age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Encoding categorical columns to visualize correlation of parameters with Purchase column\n",
    "# Importing required package\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_x = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical columns \n",
    "dataset['City_Category'] = encode_x.fit_transform(dataset['City_Category'])\n",
    "dataset['Gender_MaritalStatus'] = encode_x.fit_transform(dataset['Gender_MaritalStatus'])\n",
    "dataset['Modified_Age'] = encode_x.fit_transform(dataset['Modified_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Occupation','City_Category','Stay_In_Current_City_Years','Gender_MaritalStatus','Modified_Age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables, one for each category of a categorical variable\n",
    "dataset = pd.get_dummies(dataset, columns=['Occupation', 'City_Category','Stay_In_Current_City_Years', \n",
    "                                           'Gender_MaritalStatus','Modified_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns which have been converted to different types:\n",
    "dataset.drop(['Age','Gender', 'Marital_Status'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset back into test and train datasets for model building:\n",
    "train = dataset.loc[dataset['source']==\"train\"]\n",
    "test = dataset.loc[dataset['source']==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns:\n",
    "test = test.drop(['Purchase','source'],axis=1) # dropping dependent variable 'Purchase' from the test dataset\n",
    "train = train.drop(['source'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting csv files as modified versions:\n",
    "train.to_csv(\"./BlackFriday_Outputs/train_modified.csv\",index=False)\n",
    "test.to_csv(\"./BlackFriday_Outputs/test_modified.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean based:\n",
    "mean_purhcase = train['Purchase'].mean()\n",
    "mean_purhcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dataframe with IDs for submission:\n",
    "base1 = test[['User_ID','Product_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implying the mean sales value to the Item_Outlet_Sales column\n",
    "base1.loc[:,'Purchase'] = mean_purhcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the submission file\n",
    "base1.to_csv(\"./BlackFriday_Outputs/algor0.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to makes the model, performs cross-validation and generates submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model and perform cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def modelfit_test(algorthm, dftrain, dftest, predictors, target, IDcol):\n",
    "\n",
    "    #Fit the algorthmorithm on the data\n",
    "    algorthm.fit(dftrain[predictors], dftrain[target]) \n",
    "        \n",
    "    #Predict training set:\n",
    "    dftrain_predictions = algorthm.predict(dftrain[predictors])\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    cv_score = cross_val_score(algorthm, dftrain[predictors], dftrain[target], cv=20, n_jobs=-1,scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(np.abs(cv_score))\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\n------Model Report----\\n\")\n",
    "    print (\"RMSE : \" , np.sqrt(metrics.mean_squared_error(dftrain[target].values, dftrain_predictions)))\n",
    "    print (\"CV Score Mean : %.4g\" %(np.mean(cv_score)))\n",
    "    print (\"CV Score Std : %.4g\" %(np.std(cv_score)))\n",
    "    print (\"CV Score Min : %.4g\" %(np.min(cv_score)))\n",
    "    print (\"CV Score Max : %.4g\" %(np.max(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model, perform cross validation and export submission file.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "def modelfit(algorthm, dftrain, dftest, predictors, target, IDcol, filename):\n",
    "\n",
    "    #Fit the algorthmorithm on the data\n",
    "    algorthm.fit(dftrain[predictors], dftrain[target]) # similar to the base dataframe created above with the predictor & target columns\n",
    "        \n",
    "    #Predict training set:\n",
    "    dftrain_predictions = algorthm.predict(dftrain[predictors]) # Predicting using the predictors\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    cv_score = cross_val_score(algorthm, dftrain[predictors], dftrain[target], cv=20, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(np.abs(cv_score))\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\n------Model Report----\\n\")\n",
    "    print (\"RMSE : \" , np.sqrt(metrics.mean_squared_error(dftrain[target].values, dftrain_predictions)))\n",
    "    print (\"CV Score Mean : %.4g\" %(np.mean(cv_score)))\n",
    "    print (\"CV Score Std : %.4g\" %(np.std(cv_score)))\n",
    "    print (\"CV Score Min : %.4g\" %(np.min(cv_score)))\n",
    "    print (\"CV Score Max : %.4g\" %(np.max(cv_score)))\n",
    "    \n",
    "    #Predict on testing data:\n",
    "    dftest[target] = algorthm.predict(dftest[predictors])\n",
    "    \n",
    "    #Export submission file:\n",
    "    IDcol.append(target)\n",
    "    submission = pd.DataFrame({ x: dftest[x] for x in IDcol})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assigning Targets, ID Columns and predictors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning columns for model building\n",
    "target = 'Purchase'\n",
    "IDcol = ['User_ID','Product_ID']\n",
    "\n",
    "# Excluding Identifiers (used for submission) and dependent variable column\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a linear regression model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "alg1 = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_test(alg1, train, test, predictors, target, IDcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning columns for model building\n",
    "target = 'Purchase'\n",
    "IDcol = ['User_ID','Product_ID']\n",
    "\n",
    "# Excluding Identifiers (used for submission) and dependent variable column\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg1.fit(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the FUNCTION which takes the algorithm and data as input and makes the model \n",
    "modelfit(alg1, train, test, predictors, target, IDcol, 'algor1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef1 = pd.Series(alg1.coef_, predictors).sort_values(ascending=True)\n",
    "coef1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "coef1.plot(kind='bar', title='Model Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a list of independent varaibles to build the model\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Ridge regression model \n",
    "alg2 = Ridge(alpha=0.05,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_test(alg2, train, test, predictors, target, IDcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Decision Tree regression model \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "alg3 = DecisionTreeRegressor(max_depth=25, min_samples_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_test(alg3, train, test, predictors, target, IDcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluating best parameters by Grid Search__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required package\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg3.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\n",
    "params = [{'max_depth':[25,50,75,100],'min_samples_leaf' :[50,100,150,200]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = alg3, \n",
    "                           param_grid = params,\n",
    "                           scoring = 'neg_mean_squared_error',\n",
    "                           cv = 20,\n",
    "                           n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Decision Tree regression model with the above values\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "alg3_1 = DecisionTreeRegressor(max_depth=50, min_samples_leaf=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(alg3, train, test, predictors, target, IDcol,'./BlackFriday_Outputs/algor3_29_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE value is 3424 and the cross validation mean score is 3525.\n",
    "This indicates that there is __over-fitting__ of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Purchase'\n",
    "IDcol = ['User_ID','Product_ID']\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "alg5 = RandomForestRegressor(n_estimators=50,max_depth=25, min_samples_leaf=50,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_test(alg5, train, test, predictors, target, IDcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Purchase'\n",
    "IDcol = ['User_ID','Product_ID']\n",
    "# Making a decision tree with just **top 2** variables based on the above coeffecient values\n",
    "predictors = ['Master_Product_Category','City_Category_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit_test(alg5, train, test, predictors, target, IDcol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
